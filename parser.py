#!/usr/bin/env python2.7
# encoding: utf-8
"""
Aperture Web Journal data parser.

Extracts raw data from HTML generated by Aperture (Web Journal).
Requires special web theme.

Copyright (c) 2012 by Andrew Druchenko
"""

import sys
import os
import argparse
import re
import simplejson
from bs4 import BeautifulSoup
from collections import OrderedDict
from copy import deepcopy

decimal_check = re.compile('^\d+')
float_check = re.compile('^\d+\.\d+')
float_check_end = re.compile('\d+\.\d+$')


def parse_index(path):
    """
    Parses index.html of Web Journal

    :param path: str
    :return: json
    """
    soup = BeautifulSoup(open("%s/index.html" % path))
    res  = OrderedDict()

    img_count = 0
    p_count = 0
    for tag in soup.find_all(["dd", "p"]):

        if tag.name == "dd":
            img = tag.a.img
            img_count+=1
            img.attrs["src"] = os.path.realpath(path+"/"+img.attrs["src"])
            key = "img%i" % img_count
            res[key] = img.attrs

#            dt = filter(lambda t: str(t).find("dt")>=0,  tag.next_siblings)[0]
#            lis = filter(lambda t: str(t).find("li")>=0, dt.ul.contents)
#            res[key]["caption"] = unicode(lis[0].string).strip()
#            res[key]["keywords"] = unicode(lis[1].string).strip().split(", ") if len(lis) > 1 else None

        if tag.name == "p" and tag.get("localizable", None) == "true" and tag.get("class", [None,])[0] != "footerCopy":
            p_count+=1
            res["p%i" % p_count] = unicode(tag.contents[0])

    return res


def parse_details(data, path):
    """

    :param data: Parsed data, previously received by parse_index
    :type data: dict
    """

    res = deepcopy(data)

    for k,v in res.iteritems():
        if k.startswith("img"):
            # extract detailed data from large-%.html pages
            idx  = int(k.replace("img", ""))
            soup = BeautifulSoup(open("%s/large-%i.html" % (path, idx)))
            inf = soup.find(id="photoInfo")

            new_attrs = {}
            for kk in list(inf.children):
                kk.strong.unwrap()
                attr_name = kk.contents[0].strip().replace(":", "").lower()
                attr_value =  kk.contents[1].strip()
                new_attrs[attr_name] = filter_attributes(attr_name, attr_value)

            # update image attributes
            res[k].update(new_attrs)
            #print soup.title.string+"\n"

    return res


def filter_attributes(name, value):
    """
    Does some cleanup for GPS related attributes.
    :param name: Attribute name
    :type name: unicode
    :param value: Attribute value
    :type value: unicode
    """

    if name == "altitude":
        return decimal_check.match(value).group()

    if name in ("direction", "longitude", "latitude"):
        return float_check.match(value).group()

    if name == "keywords":
        return value.strip().split(", ")

    if name == "aperture":
        res = float_check_end.search(value)
        return res.group() if res is not None else value

    return value


def main():
    """
	Some help!
    """

    parser = argparse.ArgumentParser(description='Aperture Web Journal parser')
    parser.add_argument('-v', '--verbose')
    parser.add_argument('--path', default=None, type=unicode, nargs=1, help="Full path to Aperture Web Journal folder")
    parser.add_argument('--pretty', default=False, type=bool, nargs=1, help="Prettify JSON output (True/False)")

    args = parser.parse_args()

    if args.path is None:
        parser.print_help()
        return 0

    path = args.path[0]
    if not os.path.exists(path):
        print "Path: %s  does not exist!" % path
        return 1

    #process index file
    res = parse_index(path)
    res = parse_details(res, path)

    if args.pretty:
        print simplejson.dumps(res, indent=4)
    else:
        print simplejson.dumps(res)
    return 0


if __name__ == "__main__":
    sys.exit(main())